





import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import numpy as np
from pathlib import Path
import re
import os


def PRINTM(msg) -> None:
    print('*'*80)
    print(msg)
    print('*'*80)


WEATHER_PATH = Path("datasets/open-meteo-final.csv")
OUT_PATH = Path("datasets/nyc_pollution_weather_traffic_daily.csv")
TRAFFIC_PATH = Path("datasets/Automated_Traffic_Volume_Counts.csv")        








nyc_counties = {"New York", "Kings", "Queens", "Bronx", "Richmond"}


def preprocess_pollutant(pollutant) -> pd.DataFrame():
    pollutant_dict = {}
    years = ['2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023', '2024']
    for year in years: 
        # load current dataset, select relevant columns & rename them
        curr_df = pd.read_csv(os.path.join('datasets', 'pollution_datasets', f'ny_{pollutant.lower()}_{year}.csv'))
        curr_df = curr_df[['Date',f'{pollutant}', 'AQI', 'County']].copy()
        curr_df['Date'] = pd.to_datetime(curr_df['Date'])
        curr_df = curr_df[curr_df['County'].isin(nyc_counties)]
        pollutant_dict[year] = curr_df
        
    return pollutant_dict


o3_dict = preprocess_pollutant('Ozone')
no2_dict = preprocess_pollutant('NO2')
pm2d5_dict = preprocess_pollutant('PM2.5')
co_dict = preprocess_pollutant('CO')


o3_dict['2024']


o3_dict['2024']['County'].unique()


o3_df = pd.concat([o3_dict['2012'], o3_dict['2013'],o3_dict['2014'], o3_dict['2015'], o3_dict['2016'], o3_dict['2017'], o3_dict['2018'], o3_dict['2019'], o3_dict['2020'], o3_dict['2021'], o3_dict['2022'], o3_dict['2023'], o3_dict['2024']], axis=0).reset_index(drop=True)
no2_df = pd.concat([no2_dict['2012'], no2_dict['2013'], no2_dict['2014'], no2_dict['2015'], no2_dict['2016'], no2_dict['2017'], no2_dict['2018'], no2_dict['2019'], no2_dict['2020'], no2_dict['2021'], no2_dict['2022'], no2_dict['2023'], no2_dict['2024']], axis=0).reset_index(drop=True)
pm2d5_df = pd.concat([pm2d5_dict['2012'], pm2d5_dict['2013'], pm2d5_dict['2014'], pm2d5_dict['2015'], pm2d5_dict['2016'], pm2d5_dict['2017'], pm2d5_dict['2018'], pm2d5_dict['2019'], pm2d5_dict['2020'], pm2d5_dict['2021'], pm2d5_dict['2022'], pm2d5_dict['2023'], pm2d5_dict['2024']], axis=0).reset_index(drop=True)
co_df = pd.concat([co_dict['2012'], co_dict['2013'], co_dict['2014'], co_dict['2015'], co_dict['2016'], co_dict['2017'], co_dict['2018'], co_dict['2019'], co_dict['2020'], co_dict['2021'], co_dict['2022'], co_dict['2023'], co_dict['2024']], axis=0).reset_index(drop=True)


nyc_pollutant_df = o3_df.merge(no2_df, how='inner', on=['Date', 'County'], suffixes=('_o3', '_no2'))
nyc_pollutant_df = nyc_pollutant_df.merge(pm2d5_df, how='inner', on=['Date', 'County'], suffixes=('_no2', '_pm2.5'))
nyc_pollutant_df = nyc_pollutant_df.merge(co_df, how='inner', on=['Date', 'County'], suffixes=('_pm2.5', '_co'))


nyc_pollutant_df['County'].unique()


nyc_pollutant_df


pollutant_cols = ['Ozone','AQI_o3','NO2','AQI_no2','PM2.5','AQI_pm2.5','CO','AQI_co']

dfp = nyc_pollutant_df.copy()
dfp['Date'] = pd.to_datetime(dfp['Date'], errors='coerce')

# citywide = average across all counties/monitors per day + also daily max
agg_map = {c: ['max'] for c in pollutant_cols}

city_pollutants = (
    dfp.groupby('Date', as_index=True)[pollutant_cols]
       .agg(agg_map)
)

# flatten MultiIndex columns: e.g., Ozone_mean, Ozone_max, ...
city_pollutants.columns = [f"{c}_{stat}" for c, stat in city_pollutants.columns]
city_pollutants = city_pollutants.reset_index()

# use plain date type for clean merges
city_pollutants['Date'] = city_pollutants['Date'].dt.date
city_pollutants.head()


city_pollutants.columns = [col.replace('_max', '') for col in city_pollutants.columns]


city_pollutants.head()





def load_traffic_daily(path: Path) -> pd.DataFrame:
    """
    Takes the new traffic dataset with columns: Yr, M, D, HH, MM, Vol
    Aggregates volumes to daily totals across all segments.
    """
    df = pd.read_csv(path, low_memory=False)
    print(f"Unique boroughs in the dataset -> {df['Boro'].unique()}")
    df = df[(df['Boro'] == 'Queens') | (df['Boro'] == 'Bronx')]
    # ensure numeric
    df[["Yr","M","D","Vol"]] = df[["Yr","M","D","Vol"]].apply(pd.to_numeric, errors="coerce")

    # build datetime from Yr, M, D (ignore hour/min for daily aggregation)
    df["Date"] = pd.to_datetime(dict(year=df["Yr"], month=df["M"], day=df["D"]), errors="coerce")
    df = df.dropna(subset=["Date"])

    # aggregate citywide totals by date
    traffic_daily = (
        df.groupby("Date", as_index=False)
          .agg(
              traffic_segments_observed=("Vol","count"),
              traffic_daily_total=("Vol","sum"),
              traffic_daily_max=("Vol", "max"),
              traffic_daily_mean_segment=("Vol","mean"),
          )
    )

    # convert to plain date for safe merge
    traffic_daily["Year"] = traffic_daily["Date"].dt.year
    traffic_daily["Date"] = traffic_daily["Date"].dt.date
    return traffic_daily.sort_values("Date").reset_index(drop=True)



traffic_daily = load_traffic_daily(TRAFFIC_PATH)
print("Traffic date range:", traffic_daily["Date"].min(), "→", traffic_daily["Date"].max())
traffic_daily.shape


traffic_daily





weather_raw = pd.read_csv(WEATHER_PATH, skiprows=3)
weather_raw.columns = [c.strip().lower().replace(" (°c)", "").replace(" ", "_") for c in weather_raw.columns]

weather_raw['time'] = pd.to_datetime(weather_raw['time'], errors='coerce')
weather_raw['Date'] = weather_raw['time'].dt.date

weather_daily = (
    weather_raw.drop(columns=['time'])
               .groupby('Date', as_index=False)
               .mean(numeric_only=True)
               .rename(columns={'temperature_2m': 'temp_c_mean'})
)

weather_daily.head()


sns.histplot(data=weather_daily, x='temperature_2m_mean', color='yellow')


# compute date intersection across the three sources
d_poll = set(city_pollutants['Date'])
d_weat = set(weather_daily['Date'])
d_traf = set(traffic_daily['Date'])

common_dates = sorted(list(d_poll & d_weat & d_traf))

poll_aligned = city_pollutants[city_pollutants['Date'].isin(common_dates)].copy()
weat_aligned = weather_daily[weather_daily['Date'].isin(common_dates)].copy()
traf_aligned = traffic_daily[traffic_daily['Date'].isin(common_dates)].copy()

print("Aligned ranges:",
      min(common_dates), "→", max(common_dates),
      "| rows:", len(common_dates))






merged_citywide = (
    poll_aligned
      .merge(traf_aligned, on='Date', how='inner')
      .merge(weat_aligned, on='Date', how='inner')
      .sort_values('Date')
      .reset_index(drop=True)
)

# sanity check: there should be zero NaNs in traffic columns
#print("Any NaNs in traffic columns?",
 #     merged_citywide[['traffic_segments_observed','traffic_daily_total','traffic_daily_mean_segment']].isna().any().any())

merged_citywide.head()


merged_citywide.columns


# Add 'year' column based on the Date column
merged_citywide['year'] = pd.to_datetime(merged_citywide['Date']).dt.year

# Move 'year' to the first column, keep 'temp_c_mean' as the last column
cols = ['year'] + [c for c in merged_citywide.columns if c not in ['year']]
merged_citywide = merged_citywide[cols]


merged_citywide.drop(columns=['Year'], inplace=True)


plt.figure(figsize=(12,6))
sns.countplot(data=merged_citywide
              , x='year', fill=True, alpha=0.3, color='green')
plt.title('Number of datapoints (rows) per year')
plt.show()


merged_citywide[merged_citywide['year'] == 2012].shape


columns = ['Ozone', 'AQI_o3', 'NO2', 'AQI_no2', 'PM2.5', 'AQI_pm2.5', 'CO',
       'AQI_co', 'traffic_segments_observed', 'traffic_daily_total',
       'traffic_daily_mean_segment', 'traffic_daily_max',
       'temperature_2m_max', 'temperature_2m_mean',
       'daylight_duration_(s)', 'sunshine_duration_(s)',
       'precipitation_sum_(mm)', 'rain_sum_(mm)', 'snowfall_sum_(cm)',
       'wind_speed_10m_max_(km/h)', 'wind_gusts_10m_max_(km/h)',
       'wind_direction_10m_dominant_(°)', 'shortwave_radiation_sum_(mj/m²)',
       'et0_fao_evapotranspiration_(mm)', 'pressure_msl_max_(hpa)',
       'relative_humidity_2m_max_(%)', 'dew_point_2m_max',
       'cloud_cover_max_(%)', 'surface_pressure_max_(hpa)',
       'vapour_pressure_deficit_max_(kpa)', 'wet_bulb_temperature_2m_max',
       'precipitation_hours_(h)']


corr_df = merged_citywide[columns]

plt.figure(figsize=(20,14))
sns.heatmap(corr_df.corr(), annot=True, fmt=".2f", cmap='coolwarm')
plt.title('Correlation Between Weather Conditions and Pollutants')
plt.tight_layout()

# save before showing
plt.savefig("correlation_heatmap.png", dpi=300, bbox_inches='tight')
plt.show()


plt.figure(figsize=(10, 6))
sns.lmplot(x='traffic_daily_total', y='temperature_2m_mean', data=merged_citywide,  scatter_kws={'s': 3, 'alpha':0.3})
plt.title('How Traffic Affects Temperature')
plt.xlabel('Traffic daily total')
plt.ylabel('Temp (c) mean')
plt.tight_layout()
plt.show()


g = sns.lmplot(
    x='Ozone', 
    y='temperature_2m_max', 
    data=merged_citywide,
    scatter_kws={'s': 3, 'alpha': 0.3}
)

# Set titles and labels
g.fig.suptitle('How Ozone Affects Temperature', y=1.02)
g.set_xlabels('Ozone (max)')
g.set_ylabels('Temp (max)')

# Adjust layout
plt.tight_layout()

# save the plot ..
#g.fig.savefig("ozone_vs_temp.png", dpi=300, bbox_inches='tight')

plt.show()


sns.histplot(data=merged_citywide, x='traffic_daily_total')





wtp_df = merged_citywide


#wtp_df = pd.read_csv('datasets/pollution_traffic_weather_dataset.csv')
#wtp_df


plt.figure(figsize=(10,4))
sns.countplot(data=wtp_df, x='year', fill=True, alpha=0.8, color='green', palette='Set2')
plt.title('Number of datapoints (rows) per year')

plt.savefig('datapoints_per_year.png', dpi=300, bbox_inches='tight')
plt.show()


wtp_pollutants = wtp_df[['Ozone', 'NO2', 'CO', 'PM2.5']]
wtp_pollutants.head()





fig, axes = plt.subplots(2, 2, figsize=(10, 8))

pollutants = ['Ozone', 'NO2', 'CO', 'PM2.5']
colors= ['green', 'purple', 'red', 'orange']
for i, (ax, pollutant) in enumerate(zip(axes.flatten(), pollutants)):
    sns.histplot(
        data=wtp_df,
        x=pollutant,
        kde=True,
        color=colors[i],
        ax=ax
    )
    ax.set_xlabel(f'{pollutant} (ppm)')
    ax.set_title(f'{pollutant} Distribution')

plt.tight_layout()
plt.savefig('pollutants_distributions.png', dpi=300, bbox_inches='tight')
plt.show()



wtp_var_df = wtp_df[['Date','temperature_2m_max', 'precipitation_sum_(mm)', 'wind_speed_10m_max_(km/h)', 'relative_humidity_2m_max_(%)', 'traffic_daily_total']]
wtp_var_df





fig, axes = plt.subplots(2, 2, figsize=(10, 8))

variables = [
    'temperature_2m_mean',
    'precipitation_sum_(mm)',
    'wind_speed_10m_max_(km/h)',
    'relative_humidity_2m_max_(%)'
]

titles = [
    'Mean Temperature',
    'Daily Precipitation (mm, non-zero)',
    'Max Wind Speed (km/h)',
    'Max Relative Humidity (%)'
]

colors = ['red', 'blue', 'green', 'purple']

for ax, var, title, color in zip(axes.flatten(), variables, titles, colors):
    
    if var == 'precipitation_sum_(mm)':
        data = wtp_df[wtp_df[var] > 0]   # remove zero-precipitation days
    else:
        data = wtp_df

    sns.histplot(
        data=data,
        x=var,
        kde=True,
        ax=ax,
        color=color
    )

    ax.set_title(title)
    ax.set_ylabel('Count')

plt.tight_layout()
plt.savefig('meteorological_distributions.png', dpi=300, bbox_inches='tight')
plt.show()



wtp_df.isna().sum().sum()





plt.figure(figsize=(10,6))
sns.histplot(
    data=wtp_df,
    x='traffic_daily_total',
    kde=True,
    color='green'
)
plt.title('Daily Traffic Volume Distribution')
plt.savefig('daily_traffic_volume_distributions.png', dpi=300, bbox_inches='tight')
plt.show()





merged_citywide.to_csv('datasets/pollution_traffic_weather_dataset.csv', index=False)






























